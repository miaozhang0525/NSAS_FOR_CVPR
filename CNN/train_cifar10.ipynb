{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import utils\n",
    "import logging\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import genotypes\n",
    "import torch.utils\n",
    "import torchvision.datasets as dset\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from model import NetworkCIFAR as Network\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(\"cifar\")\n",
    "parser.add_argument('--data', type=str, default='../data', help='location of the data corpus')\n",
    "parser.add_argument('--batch_size', type=int, default=96, help='batch size')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.025, help='init learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
    "parser.add_argument('--weight_decay', type=float, default=3e-4, help='weight decay')\n",
    "parser.add_argument('--report_freq', type=float, default=50, help='report frequency')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu device id')\n",
    "parser.add_argument('--epochs', type=int, default=600, help='num of training epochs')\n",
    "parser.add_argument('--init_channels', type=int, default=36, help='num of init channels')\n",
    "parser.add_argument('--layers', type=int, default=20, help='total number of layers')\n",
    "parser.add_argument('--model_path', type=str, default='saved_models', help='path to save the model')\n",
    "parser.add_argument('--auxiliary', action='store_true', default=True, help='use auxiliary tower')\n",
    "parser.add_argument('--auxiliary_weight', type=float, default=0.4, help='weight for auxiliary loss')\n",
    "parser.add_argument('--cutout', action='store_true', default=True, help='use cutout')\n",
    "parser.add_argument('--cutout_length', type=int, default=16, help='cutout length')\n",
    "parser.add_argument('--drop_path_prob', type=float, default=0.2, help='drop path probability')\n",
    "parser.add_argument('--save', type=str, default='EXP', help='experiment name')\n",
    "parser.add_argument('--seed', type=int, default=0, help='random seed')\n",
    "parser.add_argument('--arch', type=str, default='Random_NSAS', help='which architecture to use')\n",
    "parser.add_argument('--grad_clip', type=float, default=5, help='gradient clipping')\n",
    "args = parser.parse_args([])\n",
    "\n",
    "args.save = 'eval-{}-{}'.format(args.save, time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "utils.create_exp_dir(args.save, scripts_to_save=glob.glob('*.py'))\n",
    "\n",
    "log_format = '%(asctime)s %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(args.save, 'log.txt'))\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "\n",
    "CIFAR_CLASSES = 10\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not torch.cuda.is_available():\n",
    "        logging.info('no gpu device available')\n",
    "        sys.exit(1)\n",
    "\n",
    "    np.random.seed(args.seed)\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "    cudnn.benchmark = True\n",
    "    torch.manual_seed(args.seed)\n",
    "    cudnn.enabled=True\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    logging.info('gpu device = %d' % args.gpu)\n",
    "    logging.info(\"args = %s\", args)\n",
    "\n",
    "    genotype = eval(\"genotypes.%s\" % args.arch)\n",
    "    model = Network(args.init_channels, CIFAR_CLASSES, args.layers, args.auxiliary, genotype)\n",
    "    model = model.cuda()\n",
    "\n",
    "    logging.info(\"param size = %fMB\", utils.count_parameters_in_MB(model))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion = criterion.cuda()\n",
    "    optimizer = torch.optim.SGD(\n",
    "      model.parameters(),\n",
    "      args.learning_rate,\n",
    "      momentum=args.momentum,\n",
    "      weight_decay=args.weight_decay\n",
    "      )\n",
    "\n",
    "    train_transform, valid_transform = utils._data_transforms_cifar10(args)\n",
    "    train_data = dset.CIFAR10(root=args.data, train=True, download=True, transform=train_transform)\n",
    "    valid_data = dset.CIFAR10(root=args.data, train=False, download=True, transform=valid_transform)\n",
    "\n",
    "    train_queue = torch.utils.data.DataLoader(\n",
    "      train_data, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=2)\n",
    "\n",
    "    valid_queue = torch.utils.data.DataLoader(\n",
    "      valid_data, batch_size=64, shuffle=False, pin_memory=True, num_workers=2)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, float(args.epochs))\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        scheduler.step()\n",
    "        logging.info('epoch %d lr %e', epoch, scheduler.get_lr()[0])\n",
    "        model.drop_path_prob = args.drop_path_prob * epoch / args.epochs\n",
    "\n",
    "        train_acc, train_obj = train(train_queue, model, criterion, optimizer)\n",
    "        logging.info('train_acc %f', train_acc)\n",
    "\n",
    "        valid_acc, valid_obj = infer(valid_queue, model, criterion)\n",
    "        logging.info('valid_acc %f', valid_acc)\n",
    "\n",
    "        utils.save(model, os.path.join(args.save, 'weights.pt'))\n",
    "\n",
    "\n",
    "def train(train_queue, model, criterion, optimizer):\n",
    "    objs = utils.AvgrageMeter()\n",
    "    top1 = utils.AvgrageMeter()\n",
    "    top5 = utils.AvgrageMeter()\n",
    "    model.train()\n",
    "\n",
    "    for step, (input, target) in enumerate(train_queue):\n",
    "        input = Variable(input).cuda()\n",
    "        target = Variable(target).cuda(async=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits, logits_aux = model(input)\n",
    "        loss = criterion(logits, target)\n",
    "        if args.auxiliary:\n",
    "            loss_aux = criterion(logits_aux, target)\n",
    "            loss += args.auxiliary_weight*loss_aux\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm(model.parameters(), args.grad_clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n",
    "        n = input.size(0)\n",
    "        objs.update(loss.data, n)\n",
    "        top1.update(prec1, n)\n",
    "        top5.update(prec5, n)\n",
    "\n",
    "        if step % args.report_freq == 0:\n",
    "            logging.info('train %03d %e %f %f', step, objs.avg, top1.avg, top5.avg)\n",
    "\n",
    "    return top1.avg, objs.avg\n",
    "\n",
    "\n",
    "def infer(valid_queue, model, criterion):\n",
    "    objs = utils.AvgrageMeter()\n",
    "    top1 = utils.AvgrageMeter()\n",
    "    top5 = utils.AvgrageMeter()\n",
    "    model.eval()\n",
    "\n",
    "    for step, (input, target) in enumerate(valid_queue):\n",
    "        input = Variable(input, volatile=True).cuda()\n",
    "        target = Variable(target, volatile=True).cuda(async=True)\n",
    "\n",
    "        logits, _ = model(input)\n",
    "        loss = criterion(logits, target)\n",
    "\n",
    "        prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n",
    "        n = input.size(0)\n",
    "        objs.update(loss.data, n)\n",
    "        top1.update(prec1, n)\n",
    "        top5.update(prec5, n)\n",
    "\n",
    "        if step % args.report_freq == 0:\n",
    "              logging.info('valid %03d %e %f %f', step, objs.avg, top1.avg, top5.avg)\n",
    "\n",
    "    return top1.avg, objs.avg\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
